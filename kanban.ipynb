{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kanban Metrics\n",
    "\n",
    "This is an experiment of using Jira issue changelogs to compute a historical record of a Kanban, then using that historical record to run Kaplan-Meier and Weibull survivability models and Monte Carlo simulations to gauge:\n",
    "\n",
    "1. how likely will a single issue be completed in N days\n",
    "2. how much work a team can take on over the next N days\n",
    "3. and by what date N number of work items could be completed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "\n",
    "First, let's read in some [Jira changelog data](example.csv). We do this by using the [jira.py](jira.py) utility included in this repository to export issue data directly from the Jira REST API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import lifelines\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "darkgrey = '#3A3A3A'\n",
    "lightgrey = '#414141'\n",
    "\n",
    "matplotlib.pyplot.style.use('fivethirtyeight')\n",
    "matplotlib.pyplot.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.pyplot.rcParams['lines.linewidth'] = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>project_key</th>\n",
       "      <th>issue_id</th>\n",
       "      <th>issue_key</th>\n",
       "      <th>issue_type_id</th>\n",
       "      <th>issue_type_name</th>\n",
       "      <th>issue_created_date</th>\n",
       "      <th>changelog_id</th>\n",
       "      <th>status_from_id</th>\n",
       "      <th>status_from_name</th>\n",
       "      <th>status_to_id</th>\n",
       "      <th>status_to_name</th>\n",
       "      <th>status_from_category_name</th>\n",
       "      <th>status_to_category_name</th>\n",
       "      <th>status_change_date</th>\n",
       "      <th>issue_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PRJ</td>\n",
       "      <td>55840</td>\n",
       "      <td>PRJ-1161</td>\n",
       "      <td>10004</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2020-06-01 15:49:02.582000+00:00</td>\n",
       "      <td>381910.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>To Do</td>\n",
       "      <td>3.0</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>To Do</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>2020-06-01 22:51:25.761000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PRJ</td>\n",
       "      <td>55840</td>\n",
       "      <td>PRJ-1161</td>\n",
       "      <td>10004</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2020-06-01 15:49:02.582000+00:00</td>\n",
       "      <td>383545.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>10017.0</td>\n",
       "      <td>Review</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>2020-06-03 19:02:26.924000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>PRJ</td>\n",
       "      <td>55840</td>\n",
       "      <td>PRJ-1161</td>\n",
       "      <td>10004</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2020-06-01 15:49:02.582000+00:00</td>\n",
       "      <td>384710.0</td>\n",
       "      <td>10017.0</td>\n",
       "      <td>Review</td>\n",
       "      <td>10016.0</td>\n",
       "      <td>Deployed</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>Done</td>\n",
       "      <td>2020-06-08 12:13:02.847000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>PRJ</td>\n",
       "      <td>55841</td>\n",
       "      <td>PRJ-1162</td>\n",
       "      <td>10004</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2020-06-01 15:49:37.672000+00:00</td>\n",
       "      <td>396111.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>To Do</td>\n",
       "      <td>10115.0</td>\n",
       "      <td>Prioritized</td>\n",
       "      <td>To Do</td>\n",
       "      <td>To Do</td>\n",
       "      <td>2020-06-24 14:18:03.760000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PRJ</td>\n",
       "      <td>55841</td>\n",
       "      <td>PRJ-1162</td>\n",
       "      <td>10004</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2020-06-01 15:49:37.672000+00:00</td>\n",
       "      <td>396114.0</td>\n",
       "      <td>10115.0</td>\n",
       "      <td>Prioritized</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>To Do</td>\n",
       "      <td>To Do</td>\n",
       "      <td>To Do</td>\n",
       "      <td>2020-06-24 14:19:02.728000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_id project_key  issue_id issue_key  issue_type_id issue_type_name  \\\n",
       "0           1         PRJ     55840  PRJ-1161          10004             Bug   \n",
       "1           1         PRJ     55840  PRJ-1161          10004             Bug   \n",
       "2           1         PRJ     55840  PRJ-1161          10004             Bug   \n",
       "3           1         PRJ     55841  PRJ-1162          10004             Bug   \n",
       "4           1         PRJ     55841  PRJ-1162          10004             Bug   \n",
       "\n",
       "                issue_created_date  changelog_id  status_from_id  \\\n",
       "0 2020-06-01 15:49:02.582000+00:00      381910.0         10000.0   \n",
       "1 2020-06-01 15:49:02.582000+00:00      383545.0             3.0   \n",
       "2 2020-06-01 15:49:02.582000+00:00      384710.0         10017.0   \n",
       "3 2020-06-01 15:49:37.672000+00:00      396111.0         10000.0   \n",
       "4 2020-06-01 15:49:37.672000+00:00      396114.0         10115.0   \n",
       "\n",
       "  status_from_name  status_to_id status_to_name status_from_category_name  \\\n",
       "0            To Do           3.0    In Progress                     To Do   \n",
       "1      In Progress       10017.0         Review               In Progress   \n",
       "2           Review       10016.0       Deployed               In Progress   \n",
       "3            To Do       10115.0    Prioritized                     To Do   \n",
       "4      Prioritized       10000.0          To Do                     To Do   \n",
       "\n",
       "  status_to_category_name               status_change_date  issue_points  \n",
       "0             In Progress 2020-06-01 22:51:25.761000+00:00             1  \n",
       "1             In Progress 2020-06-03 19:02:26.924000+00:00             1  \n",
       "2                    Done 2020-06-08 12:13:02.847000+00:00             1  \n",
       "3                   To Do 2020-06-24 14:18:03.760000+00:00             1  \n",
       "4                   To Do 2020-06-24 14:19:02.728000+00:00             1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OMIT_ISSUE_TYPES = ('Epic',)\n",
    "FILTER_ISSUES_SINCE = (pandas.to_datetime('today') - pandas.Timedelta(days=180)).strftime('%Y-%m-%d')\n",
    "\n",
    "DATA_FILE = 'data/example.csv'\n",
    "STATUS_ORDER = ['Prioritized', 'In Preparation', 'In Progress', 'Review', 'Accepted', 'Deployed']\n",
    "STORY_POINT_FIELD = None\n",
    "\n",
    "data = pandas.read_csv(\n",
    "    DATA_FILE, parse_dates=['status_change_date', 'issue_created_date'])\n",
    "\n",
    "# let's check to make sure the data is loaded and sorted correctly\n",
    "data = data.sort_values(['issue_id', 'status_change_date'])\n",
    "\n",
    "# let's drop duplicates based on issue_id and changelog_id\n",
    "n1 = len(data)\n",
    "data = data.drop_duplicates(subset=['issue_id', 'changelog_id'], keep='first')\n",
    "n2 = len(data)\n",
    "\n",
    "# filter out Epic specific data\n",
    "data = data[~data['issue_type_name'].isin(OMIT_ISSUE_TYPES)]\n",
    "\n",
    "# filter out issues before date\n",
    "n3 = len(data)\n",
    "data = data[data['issue_created_date'] >= FILTER_ISSUES_SINCE]\n",
    "n4 = len(data)\n",
    "if n3 == n4: \n",
    "    # if we're not filtering out any issues, set the filter date to the earliest issue date\n",
    "    FILTER_ISSUES_SINCE = data['issue_created_date'].min().strftime('%Y-%m-%d')\n",
    "\n",
    "# rename the story point field name to \"issue_points\"\n",
    "data = data.rename(columns={STORY_POINT_FIELD:'issue_points'})\n",
    "if 'issue_points' not in data:\n",
    "    data['issue_points'] = 1\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 duplicates dropped from dataset'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{n1-n2} duplicates dropped from dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Bug': 192, 'Task': 233, 'Story': 151})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(data['issue_type_name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'To Do': 194,\n",
       "         'In Progress': 229,\n",
       "         'Review': 180,\n",
       "         'Prioritized': 265,\n",
       "         nan: 106,\n",
       "         'Accepted': 49,\n",
       "         \"Can't Fix\": 23,\n",
       "         'Backlog': 1,\n",
       "         'Deployed': 104,\n",
       "         'In Preparation': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(list(data['status_from_name'].values) + list(data['status_to_name'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, let's coallesce the changelogs into individual issues changelogs for easy lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = collections.defaultdict(list)\n",
    "issue_ids = dict()\n",
    "issue_keys = dict()\n",
    "issue_types = dict()\n",
    "issue_points = dict()\n",
    "for row, item in data.iterrows():\n",
    "    issues[item.issue_id].append(item)\n",
    "    issue_types[item.issue_id] = item.issue_type_name\n",
    "    issue_ids[item.issue_key] = item.issue_id\n",
    "    issue_keys[item.issue_id] = item.issue_key\n",
    "    issue_points[item.issue_id] = item.issue_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to be able to do at this point is to know the total time an issue spends in the \"In Progress\" state. We could take a look at all of the state changes and compute the sum of the time residing in the \"In Progess\" state. An alternative that is easier to compute (with less accuracy) is to track when the issue was first created, when it first moved into work in progress, and when it finally completed, ignoring other state transitions in between.\n",
    "\n",
    "To do this without having to map each status, we use the Jira \"status_category_name\", which is an ENUM:\n",
    "\n",
    "* To Do\n",
    "* In Progress\n",
    "* Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_statuses = collections.defaultdict(dict)\n",
    "\n",
    "for issue_id, issue in issues.items():\n",
    "    for update in issue:\n",
    "        # learn when the issue was first created\n",
    "        if not issue_statuses[issue_id].get('first_created'):\n",
    "            issue_statuses[issue_id]['first_created'] = update.issue_created_date\n",
    "        issue_statuses[issue_id]['first_created'] = min(issue_statuses[issue_id]['first_created'], update.issue_created_date)\n",
    "\n",
    "        # learn when the issue was first moved to in progress\n",
    "        if update.status_to_category_name == 'In Progress':\n",
    "            if not issue_statuses[issue_id].get('first_in_progress'):\n",
    "                issue_statuses[issue_id]['first_in_progress'] = update.status_change_date\n",
    "            issue_statuses[issue_id]['first_in_progress'] = min(issue_statuses[issue_id]['first_in_progress'], update.status_change_date)\n",
    "        \n",
    "        # learn when the issue was finally moved to completion\n",
    "        if update.status_to_category_name == 'Complete' or update.status_to_category_name == 'Done':\n",
    "            if not issue_statuses[issue_id].get('last_complete'):\n",
    "                issue_statuses[issue_id]['last_complete'] = update.status_change_date\n",
    "            issue_statuses[issue_id]['last_complete'] = max(issue_statuses[issue_id]['last_complete'], update.status_change_date)\n",
    "            \n",
    "        issue_statuses[issue_id]['last_update'] = update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a new data set of each issue with the dates when the state changes happened. We also compute the lead and cycle times of each issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_data = pandas.DataFrame(columns=[\n",
    "    'issue_key',\n",
    "    'issue_type',\n",
    "    'issue_points',\n",
    "    'new',\n",
    "    'new_day',\n",
    "    'in_progress',\n",
    "    'in_progress_day',\n",
    "    'complete',\n",
    "    'complete_day',\n",
    "    'lead_time',\n",
    "    'lead_time_days',\n",
    "    'cycle_time',\n",
    "    'cycle_time_days',\n",
    "])\n",
    "\n",
    "for issue_id in issue_statuses:\n",
    "    new = issue_statuses[issue_id].get('first_created')\n",
    "    in_progress = issue_statuses[issue_id].get('first_in_progress')\n",
    "    complete = issue_statuses[issue_id].get('last_complete')\n",
    "    \n",
    "    # since numpy uses naive datetimes, let's make these progress dates naive\n",
    "    if new:\n",
    "        new = new.replace(tzinfo=None)\n",
    "    if in_progress:\n",
    "        in_progress = in_progress.replace(tzinfo=None)\n",
    "    if complete:\n",
    "        complete = complete.replace(tzinfo=None)\n",
    "    \n",
    "    if complete:\n",
    "        lead_time = complete - new\n",
    "        \n",
    "        if in_progress:\n",
    "            cycle_time = complete - in_progress\n",
    "            \n",
    "            # adjust for weekends in the cycle_time\n",
    "            weekend_days = numpy.busday_count(in_progress.date(), complete.date(), weekmask='Sat Sun')\n",
    "            cycle_time -= pandas.Timedelta(days=weekend_days)\n",
    "            \n",
    "        else:\n",
    "            cycle_time = pandas.Timedelta(days=0)\n",
    "    else:\n",
    "        lead_time = pandas.Timedelta(days=0)\n",
    "        cycle_time = pandas.Timedelta(days=0)\n",
    "    \n",
    "    issue_data = issue_data.append({\n",
    "        'issue_key': issue_keys.get(issue_id),\n",
    "        'issue_type': issue_types.get(issue_id),\n",
    "        'issue_points': issue_points.get(issue_id),\n",
    "        'new': new,\n",
    "        'new_day': None,\n",
    "        'in_progress': in_progress,\n",
    "        'in_progress_day': None,\n",
    "        'complete': complete,\n",
    "        'complete_day': None,\n",
    "        'lead_time': lead_time,\n",
    "        'lead_time_days': None,\n",
    "        'cycle_time': cycle_time,\n",
    "        'cycle_time_days': None,\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# truncate days to omit time\n",
    "issue_data['new_day'] = issue_data['new'].values.astype('<M8[D]')\n",
    "issue_data['in_progress_day'] = issue_data['in_progress'].values.astype('<M8[D]')\n",
    "issue_data['complete_day'] = issue_data['complete'].values.astype('<M8[D]')\n",
    "\n",
    "# add column for lead time represented as days\n",
    "issue_data['lead_time_days'] = issue_data['lead_time'] / pandas.to_timedelta(1, unit='D')\n",
    "# round lead time less than 1 hour to zero\n",
    "issue_data.loc[issue_data['lead_time_days'] < 1/24.0, 'lead_time_days'] = 0\n",
    "\n",
    "# add column for cycle time represented as days\n",
    "issue_data['cycle_time_days'] = issue_data['cycle_time'] / pandas.to_timedelta(1, unit='D')\n",
    "# round cycle time less than 1 hour to zero\n",
    "issue_data.loc[issue_data['cycle_time_days'] < 1/24.0, 'cycle_time_days'] = 0\n",
    "\n",
    "# add column for the last statuses of this issue\n",
    "issue_data['last_issue_status'] = [issue_statuses[issue_ids[key]].get('last_update', {}).get('status_to_name') for key in issue_data['issue_key']]\n",
    "issue_data['last_issue_status_category'] = [issue_statuses[issue_ids[key]].get('last_update', {}).get('status_to_category_name') for key in issue_data['issue_key']]\n",
    "\n",
    "issue_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "Let's take a brief look at some basic Kanban metrics, like Cycle Time & Throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle Time\n",
    "\n",
    "Cycle Time is the amount of time an issue spends \"In Progress\".\n",
    "\n",
    "In other words, it's the total duration from the moment an issue is started until it is is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_data = issue_data.copy().reset_index()\n",
    "cycle_data = cycle_data[cycle_data['complete_day'] >= pandas.to_datetime(FILTER_ISSUES_SINCE)]\n",
    "\n",
    "# drop issues with a cycle time less than 1 hour\n",
    "cycle_data = cycle_data[cycle_data['cycle_time_days'] > (1/24.0)]\n",
    "\n",
    "cycle_data['Moving Average (10 days)'] = cycle_data['cycle_time_days'].rolling(window=10).mean()\n",
    "cycle_data['Average'] = cycle_data['cycle_time_days'].mean()\n",
    "\n",
    "cycle_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15, 10))\n",
    "\n",
    "ax = seaborn.lineplot(x='issue_key', y='value', hue='variable', data=pandas.melt(cycle_data[['issue_key', 'cycle_time_days', 'Moving Average (10 days)', 'Average']], ['issue_key']))\n",
    "\n",
    "ax.set_title(\"Cycle Time Since {}\".format(FILTER_ISSUES_SINCE), loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "\n",
    "ax.set_xlabel('Issue Timeline')\n",
    "ax.set_ylabel('Days')\n",
    "\n",
    "key_ticks = range(0, len(cycle_data['issue_key']), len(cycle_data['issue_key'])//10)\n",
    "\n",
    "ax.set_xticks(key_ticks)\n",
    "\n",
    "def format_func(value, tick_number):\n",
    "    return pandas.to_datetime(cycle_data['complete_day'].values[value]).strftime('%d %b')\n",
    "ax.xaxis.set_major_formatter(matplotlib.pyplot.FuncFormatter(format_func))\n",
    "\n",
    "ax.axhline(y=0, color=lightgrey, alpha=.5);\n",
    "\n",
    "_ = ax.text(cycle_data['issue_key'].max(), cycle_data['Average'].max(), \"{:.2f}\".format(cycle_data['Average'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/cycletime-timeline.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15,10))\n",
    "\n",
    "ax = seaborn.distplot(cycle_data['cycle_time_days'], bins=100, kde=False)\n",
    "\n",
    "ax.set_title(\"Cycle Time Histogram Since {}\".format(FILTER_ISSUES_SINCE), loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('Days')\n",
    "_ = ax.set_xlim([0, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/cycletime-histogram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throughput\n",
    "\n",
    "Throughput is the number of issues completed in a given week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throughput_data = issue_data.copy()\n",
    "throughput_data = throughput_data[throughput_data['complete_day'] >= pandas.to_datetime(FILTER_ISSUES_SINCE)]\n",
    "\n",
    "points_data = pandas.pivot_table(throughput_data, values='issue_points', index='complete_day', aggfunc=numpy.sum)\n",
    "\n",
    "throughput = pandas.crosstab(throughput_data.complete_day, issue_data.issue_type, colnames=[None]).reset_index()\n",
    "\n",
    "cols = set(throughput.columns)\n",
    "cols.remove('complete_day')\n",
    "\n",
    "throughput['Throughput'] = 0\n",
    "for col in cols:\n",
    "    throughput['Throughput'] += throughput[col]\n",
    "    \n",
    "date_range = pandas.date_range(\n",
    "    start=throughput.complete_day.min(),\n",
    "    end=throughput.complete_day.max(), freq='B'\n",
    ")\n",
    "\n",
    "throughput = throughput.set_index('complete_day')\n",
    "throughput['Velocity'] = points_data['issue_points']\n",
    "\n",
    "throughput = throughput.reindex(date_range).fillna(0).astype(int).rename_axis('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throughput_per_week = pandas.DataFrame(\n",
    "    throughput['Throughput'].resample('W-Mon').sum()\n",
    ").reset_index()\n",
    "\n",
    "throughput_per_week['Moving Average (4 weeks)'] = throughput_per_week['Throughput'].rolling(window=4).mean().dropna()\n",
    "throughput_per_week['Average'] = throughput_per_week['Throughput'].mean()\n",
    "\n",
    "throughput_per_week.head(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15,10))\n",
    "\n",
    "ax = seaborn.lineplot(x='Date', y='value', hue='variable', data=pandas.melt(throughput_per_week[['Date', 'Throughput', 'Moving Average (4 weeks)', 'Average']], ['Date']))\n",
    "\n",
    "x = throughput_per_week['Date']\n",
    "y1 = throughput_per_week['Throughput']\n",
    "ax.fill_between(x, y1, color='C0', alpha=0.3,\n",
    "                 interpolate=True)\n",
    "\n",
    "ax.set_title(\"Throughput per Week Since {}\".format(FILTER_ISSUES_SINCE), loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "\n",
    "ax.set_xlabel('Week')\n",
    "ax.set_ylabel('Items Completed')\n",
    "\n",
    "ax.axhline(y=0, color=lightgrey, alpha=.5);\n",
    "\n",
    "_ = ax.text(throughput_per_week['Date'].max(), throughput_per_week['Average'].max(), \"{:.2f}\".format(throughput_per_week['Average'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/throughput-timeline.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15,10))\n",
    "\n",
    "ax = seaborn.distplot(throughput_per_week['Throughput'], kde=False)\n",
    "\n",
    "ax.set_title(\"Throughput Histogram Since {}\".format(FILTER_ISSUES_SINCE), loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "ax.set_ylabel('Frequency')\n",
    "_ = ax.set_xlabel('Throughput (per week)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/throughput-histogram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocity\n",
    "\n",
    "If we're pointing issues, we can use the points as our throughput metric instead of number of issues closed. This is not a traditional Kanban practice, but it's useful for some teams. If you've loaded data that does not include a point metric, we assume 1 point per issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_per_two_week = pandas.DataFrame(\n",
    "    throughput['Velocity'].resample('2W-Mon', closed='right').sum()\n",
    ").reset_index()\n",
    "\n",
    "velocity_per_two_week['Moving Average (2 periods)'] = velocity_per_two_week['Velocity'].rolling(window=2).mean().dropna()\n",
    "velocity_per_two_week['Average'] = velocity_per_two_week['Velocity'].mean()\n",
    "\n",
    "velocity_per_two_week.head(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15,10))\n",
    "\n",
    "ax = seaborn.lineplot(x='Date', y='value', hue='variable', data=pandas.melt(velocity_per_two_week[['Date', 'Velocity', 'Moving Average (2 periods)', 'Average']], ['Date']))\n",
    "\n",
    "x = velocity_per_two_week['Date']\n",
    "y1 = velocity_per_two_week['Velocity']\n",
    "ax.fill_between(x, y1, color='C0', alpha=0.3,\n",
    "                 interpolate=True)\n",
    "\n",
    "ax.set_title(\"Velocity per Two Week Period Since {}\".format(FILTER_ISSUES_SINCE), loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "\n",
    "ax.set_xlabel('Two Week Period')\n",
    "ax.set_ylabel('Points Completed')\n",
    "\n",
    "ax.axhline(y=0, color=lightgrey, alpha=.5);\n",
    "\n",
    "_ = ax.text(velocity_per_two_week['Date'].max(), velocity_per_two_week['Average'].max(), \"{:.2f}\".format(velocity_per_two_week['Average'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/velocity-timeline.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrivals & Departures\n",
    "\n",
    "Let's check out the arrivals and departures in the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pandas.to_datetime(FILTER_ISSUES_SINCE)\n",
    "end = pandas.to_datetime('today')\n",
    "\n",
    "wip_data = []\n",
    "\n",
    "while start <= end:\n",
    "    \n",
    "    wip_data.append({\n",
    "        'date': start,\n",
    "        'arrivals': (issue_data['new_day'] == start).sum(),\n",
    "        'departures': (issue_data['complete_day'] == start).sum(),\n",
    "    })\n",
    "    \n",
    "    start += pandas.Timedelta(days=1)\n",
    "\n",
    "wip_data = pandas.DataFrame(wip_data, columns=['date', 'arrivals', 'departures'])\n",
    "\n",
    "wip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15,10))\n",
    "\n",
    "ax = seaborn.lineplot(x='date', y='value', hue='variable', data=pandas.melt(wip_data[['date', 'arrivals', 'departures']], ['date']))\n",
    "\n",
    "x = wip_data['date']\n",
    "y1 = wip_data['arrivals']\n",
    "y2 = wip_data['departures']\n",
    "\n",
    "ax.fill_between(x, y1, y2, where=(y1 > y2), color='C0', alpha=0.3,\n",
    "                 interpolate=True)\n",
    "\n",
    "ax.fill_between(x, y1, y2, where=(y1 <= y2), color='C1', alpha=0.3,\n",
    "                 interpolate=True)\n",
    "\n",
    "ax.set_title(f\"Arrivals and Departures per Day since {wip_data['date'].min().strftime('%Y-%m-%d')}\", loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "\n",
    "ax.set_xlabel('Timeline')\n",
    "ax.set_ylabel('Items')\n",
    "\n",
    "ax.axhline(y=0, color=lightgrey, alpha=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/burndown-timeline.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Flow\n",
    "\n",
    "Understanding the flow of issues in each status is important for understanding where bottlenecks occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pandas.date_range(start=FILTER_ISSUES_SINCE, end='today', freq='D', tz='UTC')\n",
    "\n",
    "flow_data = data.copy().reset_index()\n",
    "\n",
    "statuses = set(flow_data['status_from_name']) | set(flow_data['status_to_name'])\n",
    "statuses.remove(numpy.nan)\n",
    "\n",
    "f = pandas.DataFrame(columns=['date'] + list(statuses))\n",
    "\n",
    "last_counter = None\n",
    "\n",
    "for date in dates:\n",
    "    tomorrow = date + pandas.Timedelta(days=1)\n",
    "    date_changes = flow_data\n",
    "    date_changes = date_changes[date_changes['status_change_date'] >= date]\n",
    "    date_changes = date_changes[date_changes['status_change_date'] < tomorrow]\n",
    "    \n",
    "    if last_counter:\n",
    "        counter = last_counter\n",
    "    else:\n",
    "        counter = collections.Counter()\n",
    "    for item in date_changes['status_from_name']:\n",
    "        if counter[item] > 0:\n",
    "            counter[item] -= 1\n",
    "    for item in date_changes['status_to_name']:\n",
    "        counter[item] += 1\n",
    "    \n",
    "    row = dict(counter)\n",
    "    row['date'] = date\n",
    "    f = f.append(row, ignore_index=True)\n",
    "    \n",
    "    last_counter = counter\n",
    "\n",
    "f = f.fillna(0)\n",
    "f['date'] = f['date'].dt.normalize()\n",
    "f['date'] = f['date'].dt.date\n",
    "f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_status = STATUS_ORDER[-1]\n",
    "status_columns = list(reversed(STATUS_ORDER))\n",
    "flow_columns = ['date'] + status_columns\n",
    "\n",
    "flow = f[flow_columns]\n",
    "\n",
    "y_min = flow[ending_status].min()\n",
    "y_max = flow[STATUS_ORDER].max().sum()\n",
    "\n",
    "flow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom area plot data\n",
    "flow_agg = flow[flow_columns]\n",
    "x  = flow_agg['date'] = pandas.to_datetime(flow_agg['date'])\n",
    "\n",
    "ys = []\n",
    "for status in reversed(STATUS_ORDER):\n",
    "    lasty = ys[-1] if ys else 0\n",
    "    y = flow_agg[status] = (flow_agg[status] + lasty).astype(float)\n",
    "    ys.append(y)\n",
    "    \n",
    "# melt the data to be able to be sent to lineplot\n",
    "xyz = pandas.melt(flow_agg, ['date'])\n",
    "xyz['value'] = xyz['value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15,10))\n",
    "\n",
    "ax = seaborn.lineplot(x='date', y='value', hue='variable', data=xyz)\n",
    "\n",
    "# create the area fills between lines\n",
    "lasty = 0\n",
    "for i, y in enumerate(ys):\n",
    "    ax.fill_between(x, lasty, y, color=f'C{i}', alpha=0.7,\n",
    "        interpolate=False)\n",
    "    lasty = y\n",
    "\n",
    "ax.set_title(\"Cumulative Flow Since {}\".format(flow_agg['date'].min().strftime('%Y-%m-%d')), loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "\n",
    "ax.set_xlabel('Timeline')\n",
    "ax.set_ylabel('Items')\n",
    "\n",
    "tenth = (y_max-y_min)*0.1\n",
    "\n",
    "ax.set_ylim([y_min - tenth, y_max + 2*tenth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/flow-timeline.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom area plot data\n",
    "flow_agg = flow[flow_columns]\n",
    "x  = flow_agg['date'] = pandas.to_datetime(flow_agg['date'])\n",
    "\n",
    "# create the aggregations based on the (reversed) status order\n",
    "flow_agg[status_columns] = flow_agg[status_columns].divide(flow_agg[status_columns].sum(axis=1), axis=0)\n",
    "\n",
    "ys = []\n",
    "for status in reversed(STATUS_ORDER):\n",
    "    lasty = ys[-1] if ys else 0\n",
    "    y = flow_agg[status] = (flow_agg[status] + lasty).astype(float)\n",
    "    ys.append(y)\n",
    "    \n",
    "# melt the data to be able to be sent to lineplot\n",
    "xyz = pandas.melt(flow_agg, ['date'])\n",
    "xyz['value'] = xyz['value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15,10))\n",
    "\n",
    "ax = seaborn.lineplot(x='date', y='value', hue='variable', data=xyz)\n",
    "\n",
    "# create the area fills between lines\n",
    "lasty = 0\n",
    "for i, y in enumerate(ys):\n",
    "    ax.fill_between(x, lasty, y, color=f'C{i}', alpha=0.7,\n",
    "        interpolate=False)\n",
    "    lasty = y\n",
    "\n",
    "ax.set_title(\"Normalized Cumulative Flow Since {}\".format(flow_agg['date'].min().strftime('%Y-%m-%d')), loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "\n",
    "ax.set_xlabel('Timeline')\n",
    "ax.set_ylabel('Items Percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/flow-normalized-timeline.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work In Progress\n",
    "\n",
    "We should also keep track of how much work in progress we have at any point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIP_OPEN_AT_START=0 # change this if you want to push up the baseline\n",
    "\n",
    "wip_data = issue_data[issue_data['in_progress_day'].notnull()]\n",
    "wip_data = wip_data[wip_data['last_issue_status_category'] != 'To Do']\n",
    "\n",
    "dates = pandas.date_range(start=FILTER_ISSUES_SINCE, end='today', freq='D')\n",
    "\n",
    "wip = pandas.DataFrame(columns=['date', 'WIP'])\n",
    "\n",
    "for date in dates:\n",
    "    tomorrow = date + pandas.Timedelta(days=1)\n",
    "    date_changes = wip_data\n",
    "    date_changes = date_changes[date_changes['in_progress_day'] <= date]\n",
    "    date_changes = date_changes[(date_changes['complete_day'].isnull()) | (date_changes['complete_day'] > date)]\n",
    "    \n",
    "    row = dict()\n",
    "    row['date'] = date\n",
    "    row['WIP'] = WIP_OPEN_AT_START + len(date_changes)\n",
    "    wip = wip.append(row, ignore_index=True)\n",
    "    \n",
    "wip['Moving Average (10 days)'] = wip['WIP'].rolling(window=10).mean().dropna()\n",
    "wip['Average'] = wip['WIP'].mean()\n",
    "\n",
    "# melt the data to be able to be sent to lineplot\n",
    "wip_melted = pandas.melt(wip, ['date'])\n",
    "wip_melted['value'] = wip_melted['value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15,10))\n",
    "\n",
    "ax = seaborn.lineplot(x='date', y='value', hue='variable', data=wip_melted)\n",
    "\n",
    "ax.set_title(f\"Work in Progress per Day since {wip['date'].min().strftime('%Y-%m-%d')}\", loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "\n",
    "ax.set_xlabel('Timeline')\n",
    "ax.set_ylabel('Items')\n",
    "\n",
    "ax.axhline(y=0, color=lightgrey, alpha=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/wip-timeline.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should know how much work in progress we currently have and its ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_data = issue_data[issue_data['in_progress_day'].notnull()]\n",
    "age_data = age_data[age_data['complete_day'].isnull()]\n",
    "age_data = age_data[age_data['last_issue_status_category'] != 'To Do']\n",
    "\n",
    "today = pandas.to_datetime('today')\n",
    "age_data['wip_age_days'] = (today - age_data['in_progress']) / pandas.to_timedelta(1, unit='D')\n",
    "\n",
    "age_data['wip_age_mean'] = age_data['wip_age_days'].mean()\n",
    "age_data['wip_age_P50'] = age_data['wip_age_days'].quantile(0.5)\n",
    "age_data['wip_age_P75'] = age_data['wip_age_days'].quantile(0.75)\n",
    "age_data['wip_age_P95'] = age_data['wip_age_days'].quantile(0.95)\n",
    "\n",
    "age_data.head(n=len(age_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15,10))\n",
    "\n",
    "ax = seaborn.scatterplot(x='last_issue_status', y='wip_age_days', data=age_data, s=200, sizes=(200, 200))\n",
    "\n",
    "ax = seaborn.lineplot(x='last_issue_status', y='value', hue='variable', dashes=True, data=pandas.melt(age_data[['last_issue_status', 'wip_age_P50', 'wip_age_P75', 'wip_age_P95']], ['last_issue_status']), ax=ax)\n",
    "\n",
    "ax.set_title(\"Current Work in Progess Aging\", loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "\n",
    "ax.set_xlabel('Status')\n",
    "ax.set_ylabel('Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/wip-aging.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Forecasting\n",
    "\n",
    "Welcome to the main event. Let's try to forecast the future completion of issues based on the historical distribution of throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaplan-Meier Surviability\n",
    "\n",
    "To forecast the probability of completion for a single issue, we can use our historical cycle time data and fit it into a Kaplan-Meier survivability curve.\n",
    "\n",
    "This model will allow us to forecast the probability of a single issue having a cycle time longer than a particular value (i.e., surviving past a point in time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "survivability_data = issue_data.copy()\n",
    "survivability_data = survivability_data[survivability_data['complete_day'] >= pandas.to_datetime(FILTER_ISSUES_SINCE)]\n",
    "\n",
    "durations = survivability_data['cycle_time_days']\n",
    "event_observed = [1 if c else 0 for c in survivability_data['cycle_time_days']]\n",
    "\n",
    "km = KaplanMeierFitter()\n",
    "\n",
    "## Fit the data into the model\n",
    "model = km.fit(durations, event_observed,label='Kaplan Meier Estimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15,10))\n",
    "\n",
    "ax = km.plot()\n",
    "\n",
    "ax.set_title('Issue Survivability Since {}'.format(FILTER_ISSUES_SINCE), loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "ax.set_yticks([i/100.0 for i in range(0,110,10)])\n",
    "def format_func(value, tick_number):\n",
    "    return '{}%'.format(int(value*100))\n",
    "ax.set_xlim([0, 20])\n",
    "ax.yaxis.set_major_formatter(matplotlib.pyplot.FuncFormatter(format_func))\n",
    "ax.set_ylabel('Probability of Surviving')\n",
    "_ = ax.set_xlabel('Cycle Time (Business Days)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/forecast-kaplan-meier.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How do you read this graph?*\n",
    "\n",
    "> The probability of an issue having a cycle time > 10 days (i.e., surviving past 10 days) is just over 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weibull Analysis\n",
    "\n",
    "We can also use the survivability data and fit it to a Weibull distribution. This will allow us to determine some reliability characteristics and trends of the population based on the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import WeibullFitter\n",
    "\n",
    "survivability_data = issue_data.copy()\n",
    "survivability_data = survivability_data[survivability_data['complete_day'] >= pandas.to_datetime(FILTER_ISSUES_SINCE)]\n",
    "\n",
    "durations = [c if c else 0.00001 for c in survivability_data['cycle_time_days']]\n",
    "event_observed = [1 if c else 0 for c in survivability_data['cycle_time_days']]\n",
    "\n",
    "w = WeibullFitter()\n",
    "\n",
    "## Fit the data into the model\n",
    "w.fit(durations, event_observed, label='Weibull Analysis')\n",
    "w.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15,10))\n",
    "\n",
    "ax = w.plot_survival_function()\n",
    "ax.set_yticks([i/100.0 for i in range(0,110,10)])\n",
    "ax.set_title('Issue Survivability Since {}'.format(FILTER_ISSUES_SINCE), loc='left', fontdict={\n",
    "             'fontsize': 18, 'fontweight': 'semibold'})\n",
    "ax.set_ylabel('Probability of Survival')\n",
    "ax.set_xlabel('Cycle Time (Business Days)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/forecast-weibull-survival.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Simulation\n",
    "\n",
    "So, what if you want to have a prediction of many issues over time (say, for instance, a batch of issues in an Epic)? We can use a Monte Carlo simulation based on our historical Kanban metrics to forecast the probability  of a batch of issues.\n",
    "\n",
    "We can approach this forecast from two ways:\n",
    "\n",
    "1. [WHEN]: By what date will N number of items be completed?\n",
    "2. [HOW MANY]: How many items will be completed in the next N days?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [WHEN]: By what date will N number of items be completed?\n",
    "\n",
    "The Monte Carlo simulation will use the historical distribution of throughput to forecast the future distribution of throughput.\n",
    "\n",
    "WithÂ this simulation, we can compute how long it will take to complete N number of items if the historical distribution holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATION_ITEMS = 10 # N\n",
    "SIMULATIONS = 10000\n",
    "LAST_DAYS = 90\n",
    "START_DATE = pandas.to_datetime('today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_days(data, scope):\n",
    "    days = 0\n",
    "    total = 0\n",
    "    while total <= scope:\n",
    "        total += data.sample(n=1).iloc[0]['Throughput']\n",
    "        days += 1\n",
    "    completion_date = START_DATE + pandas.Timedelta(days, unit='d')\n",
    "    return completion_date\n",
    "\n",
    "\n",
    "dataset = throughput[['Throughput']].tail(LAST_DAYS).reset_index(drop=True)\n",
    "\n",
    "samples = [simulate_days(dataset, SIMULATION_ITEMS)\n",
    "           for i in range(SIMULATIONS)]\n",
    "\n",
    "samples = pandas.DataFrame(samples, columns=['Date'])\n",
    "\n",
    "distribution_when = samples.groupby(['Date']).size().reset_index(name='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15, 10))\n",
    "\n",
    "ax = seaborn.barplot(x='Date', y='Frequency', data=distribution_when, color='C0', alpha=0.7)\n",
    "\n",
    "ax.set_title(f\"Distribution of Monte Carlo Simulation 'When' ({SIMULATIONS} Runs)\", loc='left',\n",
    "             fontdict={'size': 18, 'weight': 'semibold'})\n",
    "\n",
    "ax.set_xlabel(f\"Completion Days for {SIMULATION_ITEMS} Items\")\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "unique_dates = sorted(list(distribution_when['Date'].drop_duplicates()))\n",
    "date_ticks = range(0, len(unique_dates), len(unique_dates)//10)\n",
    "\n",
    "ax.set_xticks(date_ticks)\n",
    "\n",
    "ax.set_xticklabels([\n",
    "    (unique_dates[i] - START_DATE).days\n",
    "                    for i in date_ticks], rotation=45)\n",
    "\n",
    "ax.axhline(y=SIMULATIONS*0.001, color=darkgrey, alpha=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/distribution-montecarlo-when.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can analyze the probability of completion based on this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_when = distribution_when.sort_index(ascending=False)\n",
    "distribution_when['Probability'] = 100 - 100 * \\\n",
    "    distribution_when.Frequency.cumsum()/distribution_when.Frequency.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15, 10))\n",
    "\n",
    "ax = seaborn.barplot(x='Date', y='Probability', data=distribution_when, color='C0', alpha=0.7)\n",
    "\n",
    "ax.set_title(f\"Probabilities of Completion for {SIMULATION_ITEMS} Issues\", y=1.02, loc='left',\n",
    "    fontdict={'size': 18, 'weight': 'semibold'})\n",
    "\n",
    "ax.text(x=0, y=1,\n",
    "    s=f\"Based on a Monte Carlo Simulation ({SIMULATIONS} Runs) with throughput sampling over {LAST_DAYS} business days\",\n",
    "    fontsize=14, ha='left', va='center', transform=ax.transAxes);\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Total Business Days to Completion')\n",
    "ax.axhline(y=0.5, color=darkgrey, alpha=.5)\n",
    "ax.axhline(y=5, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=25, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=50, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=75, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=85, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=95, color=darkgrey, linestyle='--')\n",
    "\n",
    "unique_dates = sorted(list(distribution_when['Date'].drop_duplicates()))\n",
    "date_ticks = range(0, len(unique_dates), len(unique_dates)//10)\n",
    "\n",
    "xpos = 0.75 * len(unique_dates)\n",
    "\n",
    "include_date = False\n",
    "\n",
    "if include_date:\n",
    "    ax.text(y=5, x=xpos, s=f\"5% ({(samples.Date.quantile(0.05) - START_DATE).days} business days, {samples.Date.quantile(0.05).strftime('%Y-%m-%d')})\",\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "    ax.text(y=25, x=xpos, s=f\"25% ({(samples.Date.quantile(0.25) - START_DATE).days} business days, {samples.Date.quantile(0.25).strftime('%Y-%m-%d')})\",\n",
    "            va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "    ax.text(y=50, x=xpos, s=f\"50% ({(samples.Date.quantile(0.5) - START_DATE).days} business days, {samples.Date.quantile(0.5).strftime('%Y-%m-%d')})\",\n",
    "            va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "    ax.text(y=75, x=xpos, s=f\"75% ({(samples.Date.quantile(0.75) - START_DATE).days} business days, {samples.Date.quantile(0.75).strftime('%Y-%m-%d')})\",\n",
    "            va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "    ax.text(y=85, x=xpos, s=f\"85% ({(samples.Date.quantile(0.75) - START_DATE).days} business days, {samples.Date.quantile(0.85).strftime('%Y-%m-%d')})\",\n",
    "            va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "    ax.text(y=95, x=xpos, s=f\"95% ({(samples.Date.quantile(0.95) - START_DATE).days} business days, {samples.Date.quantile(0.95).strftime('%Y-%m-%d')})\",\n",
    "            va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "else:\n",
    "    ax.text(y=5, x=xpos, s=f\"5% ({(samples.Date.quantile(0.05) - START_DATE).days} business days)\",\n",
    "            va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "    ax.text(y=25, x=xpos, s=f\"25% ({(samples.Date.quantile(0.25) - START_DATE).days} business days)\",\n",
    "            va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "    ax.text(y=50, x=xpos, s=f\"50% ({(samples.Date.quantile(0.5) - START_DATE).days} business days)\",\n",
    "            va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "    ax.text(y=75, x=xpos, s=f\"75% ({(samples.Date.quantile(0.75) - START_DATE).days} business days)\",\n",
    "            va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "    ax.text(y=85, x=xpos, s=f\"85% ({(samples.Date.quantile(0.85) - START_DATE).days} business days)\",\n",
    "            va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "    ax.text(y=95, x=xpos, s=f\"95% ({(samples.Date.quantile(0.95) - START_DATE).days} business days)\",\n",
    "            va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "\n",
    "ax.set_yticks([0, 20, 40, 60, 80, 100])\n",
    "ax.set_yticklabels(labels=['0%', '20%', '40%', '60%', '80%', '100%'])\n",
    "\n",
    "ax.set_xticks(date_ticks)\n",
    "\n",
    "ax.set_xticklabels([\n",
    "    (unique_dates[i] - START_DATE).days\n",
    "                    for i in date_ticks], rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/forecast-montecarlo-when.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [HOW MANY]: How many items will be completed in the next N days?\n",
    "\n",
    "The Monte Carlo simulation will use the historical distribution of throughput to forecast the future distribution of throughput.\n",
    "\n",
    "WithÂ this simulation, we can compute how many items will be completed in the next N days if the historical distribution holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATION_DAYS = 10 # N\n",
    "SIMULATIONS = 10000\n",
    "LAST_DAYS = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = throughput[['Throughput']].tail(LAST_DAYS).reset_index(drop=True)\n",
    "samples = [dataset.sample(n=SIMULATION_DAYS, replace=True).sum()['Throughput'] for i in range(SIMULATIONS)]\n",
    "samples = pandas.DataFrame(samples, columns=['Items'])\n",
    "distribution_how = samples.groupby(['Items']).size().reset_index(name='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15, 10))\n",
    "\n",
    "ax = seaborn.barplot(x='Items', y='Frequency', data=distribution_how, color='C0', alpha=0.7)\n",
    "\n",
    "ax.set_title(f\"Distribution of Monte Carlo Simulation 'How Many' ({SIMULATIONS} Runs)\", loc='left',\n",
    "             fontdict={'size': 18, 'weight': 'semibold'})\n",
    "\n",
    "ax.set_xlabel(f\"Total Items Completed in {SIMULATION_DAYS} Business Days\")\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "ax.set_xticks(distribution_how['Items'][0::len(distribution_how['Items'])//10])\n",
    "\n",
    "ax.axhline(y=SIMULATIONS*0.001, color=darkgrey, alpha=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/distribution-montecarlo-how.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can analyze the probability of completion based on this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_how = distribution_how.sort_index(ascending=False)\n",
    "distribution_how['Probability'] = 100 * \\\n",
    "    distribution_how.Frequency.cumsum()/distribution_how.Frequency.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15, 10))\n",
    "\n",
    "ax = seaborn.barplot(x='Items', y='Probability', data=distribution_how, color='C0', alpha=0.7)\n",
    "\n",
    "\n",
    "ax.set_title(f\"Probabilities of Completion in the Next {SIMULATION_DAYS} Business Days\", y=1.02, loc='left',\n",
    "    fontdict={'size': 18, 'weight': 'semibold'})\n",
    "ax.text(x=0, y=1,\n",
    "    s=f\"Based on a Monte Carlo Simulation ({SIMULATIONS} Runs) with throughput sampling over {LAST_DAYS} business days\",\n",
    "    fontsize=14, ha='left', va='center', transform=ax.transAxes);\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Total Items Completed')\n",
    "\n",
    "ax.axhline(y=0.5, color=darkgrey, alpha=.5)\n",
    "ax.axhline(y=5, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=25, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=50, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=75, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=85, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=95, color=darkgrey, linestyle='--')\n",
    "\n",
    "label_xpos = distribution_how['Items'].max()-2\n",
    "\n",
    "ax.text(y=5, x=label_xpos, s=f'5%% (%d+ Items)' % samples.Items.quantile(0.95),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "ax.text(y=25, x=label_xpos, s=f'25%% (%d+ Items)' % samples.Items.quantile(0.75),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "ax.text(y=50, x=label_xpos, s=f'50%% (%d+ Items)' % samples.Items.quantile(0.5),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "ax.text(y=70, x=label_xpos, s=f'75%% (%d+ Items)' % samples.Items.quantile(0.25),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "ax.text(y=85, x=label_xpos, s=f'85%% (%d+ Items)' % samples.Items.quantile(0.15),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "ax.text(y=95, x=label_xpos, s=f'95%% (%d+ Items)' % samples.Items.quantile(0.05),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "\n",
    "ax.set_xticks(distribution_how['Items'][0::len(distribution_how['Items'])//10])\n",
    "\n",
    "ax.set_yticks([0, 20, 40, 60, 80, 100])\n",
    "ax.set_yticklabels(labels=['0%', '20%', '40%', '60%', '80%', '100%']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/forecast-montecarlo-how.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [HOW MANY]: How many points (velocity) will be completed in the next N days?\n",
    "\n",
    "It may also be useful to use a Monte Carlo simulation against velocity instead of just throughput.\n",
    "\n",
    "The Monte Carlo simulation will use the historical distribution of velocity to forecast the future distribution of velocity.\n",
    "\n",
    "WithÂ this simulation, we can compute how many points will be completed in the next N days if the historical distribution of velocity holds. If your data doesn't include points, velocity will equal throughput, making this graph redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATION_DAYS = 10 # N\n",
    "SIMULATIONS = 10000\n",
    "LAST_DAYS = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = throughput[['Velocity']].tail(LAST_DAYS).reset_index(drop=True)\n",
    "samples = [dataset.sample(n=SIMULATION_DAYS, replace=True).sum()['Velocity'] for i in range(SIMULATIONS)]\n",
    "samples = pandas.DataFrame(samples, columns=['Points'])\n",
    "distribution_how = samples.groupby(['Points']).size().reset_index(name='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15, 10))\n",
    "\n",
    "ax = seaborn.barplot(x='Points', y='Frequency', data=distribution_how, color='C0', alpha=0.7)\n",
    "\n",
    "ax.set_title(f\"Distribution of Monte Carlo Simulation 'How Many' ({SIMULATIONS} Runs)\", loc='left',\n",
    "             fontdict={'size': 18, 'weight': 'semibold'})\n",
    "\n",
    "ax.set_xlabel(f\"Total Points Completed in {SIMULATION_DAYS} Business Days\")\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "ax.set_xticks(distribution_how['Points'][0::len(distribution_how['Points'])//10])\n",
    "\n",
    "ax.axhline(y=SIMULATIONS*0.001, color=darkgrey, alpha=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/distribution-montecarlo-how-velocity.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can analyze the probability of completion based on this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_how = distribution_how.sort_index(ascending=False)\n",
    "distribution_how['Probability'] = 100 * \\\n",
    "    distribution_how.Frequency.cumsum()/distribution_how.Frequency.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(dpi=150, figsize=(15, 10))\n",
    "\n",
    "ax = seaborn.barplot(x='Points', y='Probability', data=distribution_how, color='C0', alpha=0.7)\n",
    "\n",
    "\n",
    "ax.set_title(f\"Probabilities of Completion in the Next {SIMULATION_DAYS} Business Days\", y=1.02, loc='left',\n",
    "    fontdict={'size': 18, 'weight': 'semibold'})\n",
    "ax.text(x=0, y=1,\n",
    "    s=f\"Based on a Monte Carlo Simulation ({SIMULATIONS} Runs) with velocity sampling over {LAST_DAYS} business days\",\n",
    "    fontsize=14, ha='left', va='center', transform=ax.transAxes);\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Total Points Completed')\n",
    "\n",
    "ax.axhline(y=0.5, color=darkgrey, alpha=.5)\n",
    "ax.axhline(y=5, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=25, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=50, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=75, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=85, color=darkgrey, linestyle='--')\n",
    "ax.axhline(y=95, color=darkgrey, linestyle='--')\n",
    "\n",
    "label_xpos = distribution_how['Points'].max()-2\n",
    "\n",
    "ax.text(y=5, x=label_xpos, s=f'5%% (%d+ Points)' % samples.Points.quantile(0.95),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "ax.text(y=25, x=label_xpos, s=f'25%% (%d+ Points)' % samples.Points.quantile(0.75),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "ax.text(y=50, x=label_xpos, s=f'50%% (%d+ Points)' % samples.Points.quantile(0.5),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "ax.text(y=70, x=label_xpos, s=f'75%% (%d+ Points)' % samples.Points.quantile(0.25),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "ax.text(y=85, x=label_xpos, s=f'85%% (%d+ Points)' % samples.Points.quantile(0.15),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "ax.text(y=95, x=label_xpos, s=f'95%% (%d+ Points)' % samples.Points.quantile(0.05),\n",
    "        va='center', ha='center', backgroundcolor='#F0F0F0')\n",
    "\n",
    "ax.set_xticks(distribution_how['Points'][0::len(distribution_how['Points'])//10])\n",
    "\n",
    "ax.set_yticks([0, 20, 40, 60, 80, 100])\n",
    "ax.set_yticklabels(labels=['0%', '20%', '40%', '60%', '80%', '100%']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.figure.savefig('images/forecast-montecarlo-how-velocity.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
